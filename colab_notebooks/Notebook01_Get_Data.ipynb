{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d0997f6-9302-4846-a77c-d81320e03a2f",
   "metadata": {},
   "source": [
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/ai2es/WAF_ML_Tutorial_Part2/blob/main/colab_notebooks/Notebook01_Get_Data.ipynb)\n",
    "\n",
    "# Notebook 01: Get Data [Colab Version]\n",
    "\n",
    "### Primary Goal: Get the dataset needed for this tutorial \n",
    "\n",
    "#### Background\n",
    "\n",
    "Like Part 1 (if you haven't looked over Part 1, please do so before jumping into these notebooks), we will continue to use the [The Storm EVent ImagRy (SEVIR) dataset](https://proceedings.neurips.cc/paper/2020/file/fa78a16157fed00d7a80515818432169-Paper.pdf). Unfortunatley, the original SEVIR dataset is about 1 TB in size, making things challenging because most will not have 1 TB free to play around with. Thus, to make a dataset that is more accessible we made ```sub-sevir```. \n",
    "\n",
    "```sub-sevir``` is a sub-sampled version of SEVIR. Specifcally, we re-sample all the images to have 48 x 48 pixels, which equates to about 8 km spatial resolution and only 1 hour of time (original has 4 hours). So in total each *scene* is the shape (12,48,48,4).\n",
    "\n",
    "To see the differences here are two youtube videos:\n",
    "\n",
    "\n",
    "1. [Original resolution](https://youtu.be/ntjNB0SAz1Y)\n",
    "2. [sub-sevir](https://youtu.be/UAEfD1p5uW8)\n",
    "\n",
    "While there are considerable differences in the resolution, there is still plenty of information to train machine learning models with. \n",
    "\n",
    "After the sub-sampling of SEVIR, the data size is now only 2 GB. Thus, **please make sure you have at least 2 GB of storage space available** before continuing from here.\n",
    "\n",
    "#### Get Data\n",
    "\n",
    "The data is hosted on zenodo: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7011372.svg)](https://doi.org/10.5281/zenodo.7011372). \n",
    "\n",
    "Zenodo is a free website that allows us to store files under 50 GB.  It also enables us to easily download those files through standard tools such as wget.\n",
    "\n",
    "If you dont want to use python to download the file, you can click on the DOI link above to mannually download the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209e654-da2a-49e4-b96c-35e569829fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget \n",
    "\n",
    "url = 'https://zenodo.org/record/7011372/files/sub-sevir.tar.gz?download=1'\n",
    "\n",
    "#fix the path here to where you want to put the file\n",
    "filename = wget.download(url,out='../datasets/sub-sevir.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ddeaeb-b470-48d7-8c6e-f4b5c4ef5c71",
   "metadata": {},
   "source": [
    "#### Open Archive\n",
    "\n",
    "The file is tarballed, or compressed to make it easier to share. To undo the compression:\n",
    "\n",
    "1. Open a terminal \n",
    "    a. on a microsoft computer open powershell (open search bar and type powershell) \n",
    "    b. on a mac/linux computer just use the terminal\n",
    "    \n",
    " \n",
    "2. Navigate to where the file is  \n",
    "    \n",
    "\n",
    "    ```cd path_to_dir``` \n",
    "\n",
    "3. untar file \n",
    "\n",
    "    ``` tar 窶度vzf sub-sevir.tar.gz ```\n",
    "    \n",
    "This should have unzipped the outer directory.\n",
    "\n",
    "The contents should look like the following: \n",
    "\n",
    "- README.md \n",
    "- sub-sevir-train.tar.gz\n",
    "- sub-sevir-val.tar.gz\n",
    "- sub-sevir-test.tar.gz \n",
    "\n",
    "I encourage you to go ahead and look over the README.md which contains meta-data for how the data were created and additional information about the dataset. It is just a plain-text file, so go ahead and open it with your favorite text editor (e.g., notepad++ etc.)\n",
    "\n",
    "You probably noticed there are more pesky .tar.gz files. We will need to decompress these too. Like before: \n",
    "\n",
    "\n",
    "1. Navigate into the sub-sevir dir \n",
    "    \n",
    "\n",
    "    ```cd sub-sevir``` \n",
    "\n",
    "3. untar training file \n",
    "\n",
    "    ``` tar 窶度vzf sub-sevir-train.tar.gz ``` \n",
    "    \n",
    "4. untar validation file \n",
    "\n",
    "    ``` tar 窶度vzf sub-sevir-val.tar.gz ``` \n",
    "    \n",
    "5. untar test file \n",
    "\n",
    "    ``` tar 窶度vzf sub-sevir-test.tar.gz ``` \n",
    "    \n",
    " \n",
    "Congrats! You have successfully downloaded the dataset and are ready to play with some neural networks and machine learning. If you want to save disk space, you can go ahead and delete the .tar.gz files after you have extracted their contents. \n",
    "\n",
    "The next notebook will help you visualize and play with some of the data before we jump into the machine learning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waf_tutorial_part2",
   "language": "python",
   "name": "waf_tutorial_part2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
